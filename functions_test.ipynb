{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#from matplotlib import scatter_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create function to Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_CollegeScorecard(columns):\n",
    "    \"\"\"\n",
    "    Read in columns from files from inside the zip file. \n",
    "    Also assign a year to each DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    columns: list,\n",
    "        columns is a list of strings matching the desired column headers\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    sheets: dictionary,\n",
    "        sheets is a dictionary of year:DataFrame pairs\n",
    "    \"\"\"\n",
    "    \n",
    "    zip_file = ZipFile('CollegeScorecard_Raw_Data.zip')\n",
    "    \n",
    "    sheets = {}\n",
    "    for year in range(1996, 2018):\n",
    "        acyear = str(year)+'_'+str(year+1)[-2:]\n",
    "        sheets[year] = pd.read_csv(zip_file.open('CollegeScorecard_Raw_Data/MERGED'+acyear+'_PP.csv'), usecols=columns)\n",
    "        sheets[year]['YEAR'] = year\n",
    "        sheets[year]['YEAR'] = pd.to_datetime(sheets[year]['YEAR'], format='%Y')\n",
    "    return sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['INSTNM', 'HIGHDEG', 'CONTROL', 'REGION', 'LOCALE', 'LO_INC_DEBT_N', 'MD_INC_DEBT_N', 'HI_INC_DEBT_N',\n",
    "           'LOAN_EVER', 'PELL_EVER', 'PCTPELL', 'ICLEVEL', 'CURROPER', 'TUITFTE', 'CDR3', 'INEXPFTE']\n",
    "sheets = read_in_CollegeScorecard(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create concatenated df of all sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_all_sheets(sheets):\n",
    "    \"\"\"\n",
    "    Concatenates DataFrames in a dictionary of DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sheets: dictionary,\n",
    "        key value pairs are year and DataFrame associated to that year\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    full_df: DataFrame\n",
    "    \"\"\"\n",
    "    for year, df in sheets.items():\n",
    "        df['iyear'] = df['YEAR']\n",
    "        if year==1996:\n",
    "            full_df = df.set_index([df.index, 'iyear'])\n",
    "        else:\n",
    "            full_df = pd.concat([full_df, df.set_index([df.index, 'iyear'])])\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154228, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = concatenate_all_sheets(sheets)\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Fill huge DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_fill_from_year(df, year):\n",
    "    fill_values = {}\n",
    "    for name in df.INSTNM.unique():\n",
    "        fill_values[name] = {'LOCALE': df.loc[(df.INSTNM==name)].LOCALE.values[0], \n",
    "                             'CURROPER': df.loc[(df.INSTNM==name)].CURROPER.values[0],\n",
    "                             'CONTROL': df.loc[(df.INSTNM==name)].CONTROL.values[0]}\n",
    "    \n",
    "    for name in df.loc[df.YEAR!=year].INSTNM.unique():\n",
    "        fill_values[name] = fill_values.get(name, {'LOCALE': np.NaN, 'CURROPER': np.NaN, 'CONTROL': np.NaN})\n",
    "    \n",
    "    df.LOCALE = df.INSTNM.map(lambda name: fill_values[name]['LOCALE'])\n",
    "    df.CURROPER = df.INSTNM.map(lambda name: fill_values[name]['CURROPER'])\n",
    "    df.CONTROL = df.INSTNM.map(lambda name: fill_values[name]['CONTROL'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14233 entries, 0 to 7174\n",
      "Data columns (total 18 columns):\n",
      "INSTNM           14233 non-null object\n",
      "HIGHDEG          14233 non-null int64\n",
      "CONTROL          14233 non-null int64\n",
      "REGION           14233 non-null int64\n",
      "LOCALE           6614 non-null float64\n",
      "CURROPER         7058 non-null float64\n",
      "TUITFTE          13322 non-null float64\n",
      "INEXPFTE         13323 non-null float64\n",
      "PCTPELL          12718 non-null float64\n",
      "CDR3             12307 non-null float64\n",
      "LO_INC_DEBT_N    7156 non-null object\n",
      "MD_INC_DEBT_N    7156 non-null object\n",
      "HI_INC_DEBT_N    7156 non-null object\n",
      "LOAN_EVER        6976 non-null object\n",
      "PELL_EVER        6976 non-null object\n",
      "ICLEVEL          14233 non-null int64\n",
      "YEAR             14233 non-null datetime64[ns]\n",
      "iyear            14233 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(6), int64(4), object(6)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14233 entries, 0 to 7174\n",
      "Data columns (total 18 columns):\n",
      "INSTNM           14233 non-null object\n",
      "HIGHDEG          14233 non-null int64\n",
      "CONTROL          14233 non-null int64\n",
      "REGION           14233 non-null int64\n",
      "LOCALE           13157 non-null float64\n",
      "CURROPER         13977 non-null float64\n",
      "TUITFTE          13322 non-null float64\n",
      "INEXPFTE         13323 non-null float64\n",
      "PCTPELL          12718 non-null float64\n",
      "CDR3             12307 non-null float64\n",
      "LO_INC_DEBT_N    7156 non-null object\n",
      "MD_INC_DEBT_N    7156 non-null object\n",
      "HI_INC_DEBT_N    7156 non-null object\n",
      "LOAN_EVER        6976 non-null object\n",
      "PELL_EVER        6976 non-null object\n",
      "ICLEVEL          14233 non-null int64\n",
      "YEAR             14233 non-null datetime64[ns]\n",
      "iyear            14233 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(6), int64(4), object(6)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([sheets[2017], sheets[2016]]).info())\n",
    "back_fill_from_year(pd.concat([sheets[2017], sheets[2016]]), 2017).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 154228 entries, (0, 1996-01-01 00:00:00) to (7057, 2017-01-01 00:00:00)\n",
      "Data columns (total 17 columns):\n",
      "INSTNM           154228 non-null object\n",
      "HIGHDEG          154228 non-null int64\n",
      "CONTROL          154205 non-null float64\n",
      "REGION           154227 non-null float64\n",
      "LOCALE           6614 non-null float64\n",
      "CURROPER         7058 non-null float64\n",
      "TUITFTE          133780 non-null float64\n",
      "INEXPFTE         133775 non-null float64\n",
      "PCTPELL          67384 non-null float64\n",
      "CDR3             47815 non-null float64\n",
      "LO_INC_DEBT_N    137486 non-null object\n",
      "MD_INC_DEBT_N    137486 non-null object\n",
      "HI_INC_DEBT_N    137486 non-null object\n",
      "LOAN_EVER        137342 non-null object\n",
      "PELL_EVER        137342 non-null object\n",
      "ICLEVEL          154205 non-null float64\n",
      "YEAR             154228 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(9), int64(1), object(6)\n",
      "memory usage: 20.5+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7058 entries, 0 to 7057\n",
      "Data columns (total 18 columns):\n",
      "INSTNM           7058 non-null object\n",
      "HIGHDEG          7058 non-null int64\n",
      "CONTROL          7058 non-null int64\n",
      "REGION           7058 non-null int64\n",
      "LOCALE           6614 non-null float64\n",
      "CURROPER         7058 non-null int64\n",
      "TUITFTE          6593 non-null float64\n",
      "INEXPFTE         6593 non-null float64\n",
      "PCTPELL          6291 non-null float64\n",
      "CDR3             6055 non-null float64\n",
      "LO_INC_DEBT_N    0 non-null float64\n",
      "MD_INC_DEBT_N    0 non-null float64\n",
      "HI_INC_DEBT_N    0 non-null float64\n",
      "LOAN_EVER        0 non-null float64\n",
      "PELL_EVER        0 non-null float64\n",
      "ICLEVEL          7058 non-null int64\n",
      "YEAR             7058 non-null datetime64[ns]\n",
      "iyear            7058 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(10), int64(5), object(1)\n",
      "memory usage: 992.6+ KB\n"
     ]
    }
   ],
   "source": [
    "sheets[2017].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['CDR3', 'CONTROL'], inplace=True)\n",
    "df = df.replace('PrivacySuppressed', np.NaN)\n",
    "df.dropna(subset=['LO_INC_DEBT_N', 'MD_INC_DEBT_N', 'HI_INC_DEBT_N'], inplace=True)\n",
    "df['Public_or_Private'] = df.CONTROL.map({2:0, 1:1, 3:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logistic_regression(df, predictor_columns, predicted_column):\n",
    "    \"\"\"\n",
    "    Creates a logistic regression from input column names to predictor column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe\n",
    "        the dataframe's columns should include the predictor_columns and predicted_column\n",
    "    \n",
    "    predictor_columns: list\n",
    "        Should be a subset of columns from df. \n",
    "        Should have empty intersection with predicted_column\n",
    "    \n",
    "    predicted_column: string\n",
    "        Should be an element in the list of columns from df. \n",
    "        Should not be included in predictor_columns\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    logreg: logistic regression already trained on training data from predictor columns\n",
    "    \n",
    "    Note: This function will change the given dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create dataframes( or series) with predictors and  predicted values\n",
    "    X = df[predictor_columns]\n",
    "    y = df[predicted_column]\n",
    "    \n",
    "    # Scale the data using Robust Scaler\n",
    "    scale = RobustScaler()\n",
    "    transformed = scale.fit_transform(X)\n",
    "    X = pd.DataFrame(transformed, columns = X.columns)\n",
    "    \n",
    "    # Create Train and Test Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    \n",
    "    # Create a logistic regression model\n",
    "    logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='lbfgs')\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    try:\n",
    "        model_log = logreg.fit(X_train, y_train)\n",
    "    except:\n",
    "        model_log = logreg.fit(np.array(X_train).reshape(-1,1), y_train)\n",
    "        \n",
    "    # Add new columns to the given data frame with predicted values and probability of correct predictions\n",
    "    try:\n",
    "        df['Predicted_'+predicted_column] = logreg.predict(X)\n",
    "        df['ProbCorrect_Predicted_'+predicted_column] = logreg.predict_proba(X)[:,1]\n",
    "    except:\n",
    "        df['Predicted_'+predicted_column] = logreg.predict(np.array(X).reshape(-1,1))\n",
    "        df['ProbCorrect_Predicted_'+predicted_column] = logreg.predict_proba(np.array(X).reshape(-1,1))[:,1]\n",
    "    \n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426352841647279"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test create_logistic_regression\n",
    "\n",
    "create_logistic_regression(df, ['CDR3', 'HI_INC_DEBT_N'], 'Public_or_Private'\n",
    "                          ).score(df[['CDR3', 'HI_INC_DEBT_N']], df['Public_or_Private'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
